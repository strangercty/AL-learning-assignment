{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SET-UP: Training a Classifier with PyTorch\n",
    "==================================\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "mytrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "mytestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "mydataiter = iter(mytrainloader)\n",
    "myimages, mylabels = mydataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(myimages))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[mylabels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolutional Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "mynet = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "mycriterion = nn.CrossEntropyLoss()\n",
    "myoptimizer = optim.SGD(mynet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def train(trainloader):\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            myoptimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = mynet(inputs)\n",
    "            loss = mycriterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            myoptimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return outputs\n",
    "\n",
    "myoutputs = train(mytrainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the testset and compare the predictions to the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataiter = iter(mytestloader)\n",
    "myimages, mylabels = mydataiter.next()\n",
    "myoutputs = mynet(myimages)\n",
    "_, mypredicted = torch.max(myoutputs, 1)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(myimages))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[mylabels[j]] for j in range(4)))\n",
    "print('Predicted  : ', ' '.join('%5s' % classes[mypredicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "The higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at how the network performs on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def getAccuracy(testloader):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = mynet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        correct / total * 100.))\n",
    "    return correct / total * 100.\n",
    "    \n",
    "myaccuracy = getAccuracy(mytestloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While those results are far from perfect (we will try to make them better in the next exercises), they still look better than random chance, which is 10% accuracy (randomly picking a class out of 10 classes).\n",
    "It looks like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in mytestloader:\n",
    "        images, labels = data\n",
    "        outputs = mynet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE 1: Supervised Learning & Learning Curves\n",
    "===========================================\n",
    "\n",
    "Now, let's build a first learning curve to see how the classifier's accuracy improves with the amount of data that is used to train it. To do that, we will add data progressively, batch after after, and plot the distribution of the accuracy vs. the number of records used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run ActiveLearningClass.ipynb\n",
    "\n",
    "num_steps = 5     # <---- Play with those values. CIFAR-10 has 50,000 records for training, and 10,000 for testing\n",
    "maximum = 10000   # <----\n",
    "nps = int(maximum / num_steps)\n",
    "\n",
    "myActiveStrategy = ActiveStrategy(mynet, nsteps=num_steps)\n",
    "\n",
    "myActiveStrategy.verbose = False\n",
    "\n",
    "myActiveStrategy.init_loaders()\n",
    "myActiveStrategy.incremental_supervised()\n",
    "mySupervised = myActiveStrategy.run_experiment(num_steps, maximum)\n",
    "    \n",
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised, '--b', marker=\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the accuracy increases (overall) when more training data is added to train the model. \n",
    "\n",
    "QUESTION: What additional experiment(s) would you run to gain more understanding of the training set? What is the purpose of running such an experiment?\n",
    "\n",
    "The question now is, can we do better? That's the question that Active Learning is trying to address...\n",
    "\n",
    "In the next exercise, we will start with the easiest, most intuitive Active Learning strategy: confidence-level.\n",
    "\n",
    "\n",
    "EXERCISE 2: Uncertainty-Based Strategies\n",
    "===================================\n",
    "\n",
    "Pooling Approach with Uncertainty-Based Strategy\n",
    "------------------------------------------------------------\n",
    "\n",
    "Let's start with the very first loop. We will select go through the following steps: \n",
    "1. We will select the first training set randomly.\n",
    "2. We will train the model with that sample.\n",
    "3. We will use the trained model for inferrence on the rest of the dataset.\n",
    "4. We will select the 'nps' records with the lowest confidence and retrain the model with it.\n",
    "\n",
    "Below, we perfect step 1. and 2.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "\n",
    "unlabeled = [i for i in range(len(trainset))]\n",
    "labeled   = []\n",
    "\n",
    "to_be_labeled = # generate a random sample of the data, size nps (defined previously)\n",
    "unlabeled = # update the unlabeled array once you defined to_be_labeled\n",
    "\n",
    "myActiveStrategy.run_one(to_be_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the very first loop. We will select go through the following steps: \n",
    "1. We will select the first training set randomly.\n",
    "2. We will train the model with that sample.\n",
    "3. We will use the train model for inferrence on the rest of the dataset.\n",
    "\n",
    "We just trained the model using a random sample of size 'nps' (the size we choose for each step), to initialize our Active Learning process.\n",
    "\n",
    "Now, let's move on to step 3. and 4.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myResults = myActiveStrategy.infer(unlabeled)\n",
    "\n",
    "# Below, we update the to_be_labeled and unlabeled arrays, in preparation for the next loop...\n",
    "# the strategy is to select the records that were inferred with the lowest confidence in the previous loop...\n",
    "sorted_by_conf = # fill here; remember that the size of the array will be 'nps'\n",
    "\n",
    "# update to_be_labeled:\n",
    "to_be_labeled.extend(''' the data that should be added to the rest before retraining ''')\n",
    "unlabeled = # update unlabeled\n",
    "\n",
    "# And run one more loop...\n",
    "accuracy = myActiveStrategy.run_one(to_be_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement the whole process and run all the loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def confidenceAL(nsteps, stepSize):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    unlabeled = [i for i in range(len(trainset))]\n",
    "    labeled   = []\n",
    "\n",
    "    to_be_labeled = # ???\n",
    "    unlabeled = # ???\n",
    "    myres = myActiveStrategy.run_one(to_be_labeled)\n",
    "    results.append(myres)\n",
    "    \n",
    "    for n in range(1, nsteps):\n",
    "        # Fill algorithm here getting inspiration from the previous exercise\n",
    "        \n",
    "    return results\n",
    "    \n",
    "myConfidenceAL = confidenceAL(num_steps, nps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aren't you curious to know how good those results are? We can now compare the learning curve that we obtain with the one we got for the supervised approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,   '--b',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL, '--r',\n",
    "         marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the ActiveStrategy Class already comes with a method you can use to \"onboard\" any querying strategy you would like. Here is how it works:\n",
    "\n",
    "\n",
    "Implement the confidence level based strategy using this method.\n",
    "Then, run the process; you can move on to the next exercise while training is in progress here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def update_function(inferred_res, nRec):\n",
    "    ranked = # Sort and select the best nRec elements\n",
    "    selected = [rec[0] for rec in ranked]\n",
    "    return selected\n",
    "    \n",
    "myConfidenceAL2 = myActiveStrategy.run_ConfidenceAL(update_function, num_steps, maximum)\n",
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,    '--b',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL,  '--r',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL2, '--g',\n",
    "         marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for our strategy, we have been selecting the records for which the lowest confidence was observed in inferrence, assuming that these data points would be the ones that the model is the most confused about. While this is a sound strategy with a fairly clean dataset, in real life, it could lead to injecting more and more spam/noise into the training set.\n",
    "\n",
    "To help, let's start by drawing the distribution of the confidence level for the last inferences we ran:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inferred_CL = [ c[3].item() for c in myResults ]\n",
    "print(inferred_CL[:10])\n",
    "print(len(inferred_CL))\n",
    "\n",
    "n, bins, patches = plt.hist(x=inferred_CL, bins=30, color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Confidence of Prediction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Level')\n",
    "maxfreq = n.max()\n",
    "\n",
    "plt.ylim(top=(np.ceil(maxfreq / 10) * 10 * 1.05) if maxfreq % 10 else (maxfreq + 10) * 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: Before moving on, discuss what a good choice for nps might be here (so far, we have taken that value arbitrarily). What experient would you design to automatically choose an optimal \"nps\" value. Please discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Better Confidence Level-Based Strategy\n",
    "--------------------------------------------------\n",
    "\n",
    "Implement an alternative confidence level-based strategy where very low confidence records get cut out, and where you selected the lowest confidence records from the \"medium\" confidence sample. Experiment with different cutoffs and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/jprendki/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3267\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-c3a50f2b0cc7>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', '\\ndef update_CL_improved(inferred_res, nRec, nFilter=500): # <--- we can play with nFilter value later\\n    ranked = # ???\\n    selected = # ???\\n    return selected\\n\\nmyConfidenceAL3 = myActiveStrategy.run_ConfidenceAL(update_CL_improved, num_steps, maximum)\\nplt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,    \\'--b\\',\\n         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL2, \\'--g\\',\\n         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL3, \\'--p\\',\\n         marker=\"o\")\\n')\n",
      "  File \u001b[1;32m\"/Users/jprendki/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2323\u001b[0m, in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(magic_arg_s, cell)\n",
      "  File \u001b[1;32m\"<decorator-gen-62>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35mtime\u001b[0m\n",
      "  File \u001b[1;32m\"/Users/jprendki/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/Users/jprendki/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\"\u001b[0m, line \u001b[1;32m1235\u001b[0m, in \u001b[1;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/jprendki/anaconda3/lib/python3.7/site-packages/IPython/core/compilerop.py\"\u001b[0;36m, line \u001b[0;32m100\u001b[0;36m, in \u001b[0;35mast_parse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ranked = # ???\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def update_CL_improved(inferred_res, nRec, nFilter=500): # <--- we can play with nFilter value later\n",
    "    ranked = # ???\n",
    "    selected = # ???\n",
    "    return selected\n",
    "\n",
    "myConfidenceAL3 = myActiveStrategy.run_ConfidenceAL(update_CL_improved, num_steps, maximum)\n",
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,    '--b',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL2, '--g',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL3, '--p',\n",
    "         marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Exercise:\n",
    "----------------------\n",
    "WARNING: THIS IS VERY LONG TO RUN!!! You're invited to try it after the session, or after you are done with the other steps.\n",
    "\n",
    "Let's draw the final accuracy as a function of the 'nFilter' value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "finalAccuracies = []\n",
    "stepValues = [500, 1000, 2000, 5000] # <-- customize this to experiment different values\n",
    "for nf in stepValues:\n",
    "    print(\">>>>> Running algorithm for {0}\".format(nf))\n",
    "    myAcc = # Fill here\n",
    "    finalAccuracies.append(myAcc)\n",
    "\n",
    "plt.plot(stepValues, [a[-1] for a in finalAccuracies] , '--b', marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: What are the learning from the plot that you obtained? What further studies does this inspire to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming Approach with Uncertainty-Based Strategy\n",
    "---------------------------------------------------------------\n",
    "\n",
    "Now, instead of a pooling approach, let's use a streaming approach. Instead of using a fixed number of records at each step, you can now use a rule; for instance, instead of selecting 'n' best records, use a threshold in confidence level. What are the benefits and challenges with each methodology?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def update_streaming(inferred_res, threshold=0.075):\n",
    "    next_loop = # Fill here\n",
    "    return next_loop\n",
    "    \n",
    "myStreamingAL, myStepSizes = myActiveStrategy.run_StreamingAL(update_streaming, num_steps, maximum)\n",
    "plt.plot(myStepSizes, myStreamingAL , '--b', marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the threshold based a certain percentile value for the inferred array (in other term, we choose what percentage of the data we keep at each step). Does that remind you of something? :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_streaming_perc(inferred_res, threshold=5): # <-- here, threshold is the amount of data we want to keep\n",
    "    # Using the np.percentile function, fill the function\n",
    "    \n",
    "myStreamingAL2, myStepSizes2 = myActiveStrategy.run_StreamingAL(update_streaming_perc, num_steps, maximum)\n",
    "plt.plot(myStepSizes2, myStreamingAL2 , '--b', marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: In the code above, a major approximation was made. Do you see what it is, and how would you change it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin Sampling-Based Strategy\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import operator\n",
    "\n",
    "# Explain what this function does...\n",
    "def update_margin(inferred_res, nRec):\n",
    "    for k in len(inferred_res):\n",
    "        inferred_res[k].extend(zip(*sorted(enumerate(inferred_res[k]), key=operator.itemgetter(1)))[0][-2:])\n",
    "    ranked = sorted(inferred_res, key=lambda x: x[5] - x[4], reverse=False)[:nRec]\n",
    "    selected = [rec[0] for rec in ranked]\n",
    "    return selected\n",
    "\n",
    "myConfidenceAL4 = myActiveStrategy.run_ConfidenceAL(update_function, num_steps, maximum)\n",
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,    '--b',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL3, '--g',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL4, '--p',\n",
    "         marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a different type of strategy, called:\n",
    "\n",
    "\n",
    "EXERCISE 3: Query-By-Committee Strategies\n",
    "=====================================\n",
    "\n",
    "For Query-By-Committee strategies, we will take an approach similar to ensemble methods in Supervised Learning.\n",
    "Instead of training only one classifier, we will train several algorithms, and decide on which data to select for the next loop based on the level of disagreement between them.\n",
    "\n",
    "For our case, we could use several variations (with slightly different hyperparameters) of the same model and start by initializing different similar classifiers.\n",
    "\n",
    "Using the code below, try to run a QbC strategy by making the necessary adjustements on the model. What changes are necessary, and does the model actually need to be modified? Please comment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "unlabeled = [i for i in range(len(trainset))]\n",
    "labeled   = []\n",
    "\n",
    "to_be_labeled = random.sample(unlabeled, nps)\n",
    "unlabeled = [i for i in range(len(unlabeled)) if i not in to_be_labeled]\n",
    "\n",
    "myAccuracy1 = myActiveStrategy.run_one(to_be_labeled)\n",
    "myResults1  = myActiveStrategy.infer(unlabeled)\n",
    "myAccuracy2 = myActiveStrategy.run_one(to_be_labeled)\n",
    "myResults2  = myActiveStrategy.infer(unlabeled)\n",
    "myAccuracy3 = myActiveStrategy.run_one(to_be_labeled)\n",
    "myResults3  = myActiveStrategy.infer(unlabeled)\n",
    "\n",
    "disagreement = []\n",
    "\n",
    "for r in range(len(unlabeled)):\n",
    "    dis = 0\n",
    "    if myResults1[r][2] != myResults2[r][2]:\n",
    "        dis += 1\n",
    "    if myResults2[r][2] != myResults3[r][2]:\n",
    "        dis += 1\n",
    "    if myResults1[r][2] != myResults3[r][2]:\n",
    "        dis += 1\n",
    "    disagreement.append(dis)\n",
    "    \n",
    "print(disagreement[0:10])\n",
    "    \n",
    "print(\"No        disagreements: {0} \\n\".format(disagreement.count(0)), \n",
    "      \"One (1)   disagreement : {0} \\n\".format(disagreement.count(1)), \n",
    "      \"Two (2)   disagreements: {0} \\n\".format(disagreement.count(2)), \n",
    "      \"Three (3) disagreements: {0} \\n\".format(disagreement.count(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement use the previous approach as our querying strategy. Note that this takes a long time to run, so you're encouraged that you reduce your 'num_steps' and 'maximum' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QbCAL(nsteps, stepSize):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    unlabeled = [i for i in range(len(trainset))]\n",
    "    labeled   = []\n",
    "\n",
    "    # Randomly sample what is to be labeled first...\n",
    "    to_be_labeled = # ???\n",
    "    unlabeled = # ???\n",
    "    \n",
    "    for n in range(0, 4):\n",
    "        # Fill the function by following the same logic that previously within a loop\n",
    "        \n",
    "    return results\n",
    "    \n",
    "myQbCAL = QbCAL(num_steps, nps)\n",
    "\n",
    "plt.plot([nps*i for i in range(1, num_steps + 1)], mySupervised,    '--b',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myConfidenceAL4, '--g',\n",
    "         [nps*i for i in range(1, num_steps + 1)], myQbCAL,         '--p',\n",
    "         marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE 4: Build-Your-Own Strategy\n",
    "===============================\n",
    "\n",
    "Now, using what you have learned, develop the best querying strategy you can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
